Computer networks can't feel or understand jokes, but software engineers have hardwired some compassion.
Mechanisms in place in Facebook's system and in Google's search engine can look for suicidal messages and direct people to help.
Facebook is encouraging its 800 million users to use a system the company created to flag suicidal or otherwise violent messages. If someone is posting unsettling photos or writing status updates about killing himself or herself, friends can click on a "report suicidal content" link.
At Facebook, staff members are monitoring these reports at all times of the day, a spokesman told CNN in June. Facebook investigates each report and may send a suicidal person an e-mail offering phone numbers for suicide hot lines, he said.
That feature has been around since at least the summer, but Facebook said in a statement on Tuesday that it is expanding a partnership with the National Suicide Prevention Lifeline, which is funded by the Substance Abuse and Mental Health Services Administration.
In addition to phone support, the lifeline will now let Facebook users communicate with suicide prevention specialists in a Web chat room, the statement said.
The national suicide hot line and Facebook have been partnering since 2006, lifeline project director John Draper said in a statement.
Google added a feature to its U.S. search engine in April 2010 that displays a picture of a red telephone and the phone number for the lifeline when people are searching for suicide-related topics. Earlier, the company launched a similar feature for a poison-control hot line after receiving an e-mail from a mother who had trouble finding the number when her daughter ingested something poisonous, a Google spokeswoman said.
"In times of crisis, it's important to try to help people by quickly providing information," the spokeswoman wrote in an e-mail. "It's a privilege for Google to be working with the NSPL and to be providing support on this important issue."
