We all like to think medical care is about science, but too often it's about professional interests.
Last week, a 25-year follow-up of the Canadian National Breast Screening Study was published -- one of the eight major randomized trials of screening mammography. The headline was simple: Mammogram screenings don't reduce cancer death rates.
The reaction by some American mammographers was predictable -- discredit the study. It's predictable because it is exactly what they did when they didn't like the first findings of the study published more than 20 years ago.
The effort by the American College of Radiology to discredit the Canadian trial relies on two allegations:
The investigators were cheating: Let's look at the background on this. Randomized trials are a critical tool for clinical researchers. Study participants are placed at random in either one group (in this case those who get mammograms) or the other (those who do not). Who is in which group is solely based on the play of chance -- a flip of a coin.
The allegation of cheating -- purposely putting women whom researchers knew had advanced cancers in the mammography group -- is an incredibly serious one. It sure was taken seriously by Canada's National Cancer Institute. It launched a two-year independent review of the entire randomization process. In 1997, the review found no credible evidence of cheating.
But that didn't stop the allegation from being trotted out last week. The new study provides evidence that randomization did exactly what it is supposed to do: It created two identical groups of women. The rate of death in the two groups was exactly the same, every year, for 25 years. That can't happen by cheating -- that can only happen when the groups are formed solely by chance.
Canada is a Third World country: More specifically, the Canadians used old mammography machines that produced inadequate images, interpreted by inadequate mammographers.
It sounded as if Canada were Botswana, as if the nation had only recently gotten electric power and was still struggling to train doctors.
For mammographers who need to point to the benefits demonstrated by earlier trials of mammography, this is an odd allegation. Why? Because the other trials used even older technology. In fact, one of the trials most favorable to screening -- the Health Insurance Plan of New York's -- dates from two decades before Canada's, in the early 1960s, when mammography technologies were primitive.
Yet, in both New York and Canada, outmoded technology did exactly what it was supposed to do. It found small breast cancers.
Armed with these two allegations, the mammographers followed a well-worn strategy: Make the allegations often and loudly enough and maybe they will stick.
To be clear, not all mammographers share this view. A new generation has openly acknowledged the problems of mammography. But many in the old guard are more likely to attack any suggestion that screening doesn't work as well as advertised, characterizing researchers who raise the possibility as "malicious" or "dangerous" and questioning the editorial policies of the journals that publish their work.
It's time to stop the unfounded allegations. It might be standard procedure for politics but not for science. Too much energy has been devoted to discrediting the Canadian study and not enough to understanding it.
To make sense of information the Canadian trial offers, you need to understand its unique design -- specifically what is being compared with what. Most of the other randomized trials simply compared regular mammography with doing nothing.
In the Canadian trial, one group received a regular physical exam of the breast -- a very careful exam performed by specially trained nurses. The other group received the same regular physical exam plus regular mammography. In other words, the trial tested the usefulness of adding mammography to a physical exam in an effort to detect abnormalities that are too small to feel.
And the trial showed that finding these "too small to feel" abnormalities doesn't help women live longer.
That's really important information. It doesn't mean that mammography can't help at all -- it is extremely challenging to standardize a physical exam of the breast across an entire population. It does mean, however, that if we are going to do mammography, we should be using it to find big, important things -- not small, unimportant things.
Further, the Canadian trial confirms that the harm of being overdiagnosed by screening mammography is real: One in five invasive cancers found by screening represents overdiagnosis. Overdiagnosis happens when cellular abnormalities meet the pathologic definition of "cancer," yet never progress to cause clinical disease. Overdiagnosed women are told they have cancer, are treated for cancer, yet their "cancer" is not destined to cause them any problems.
It is important to recognize this estimate doesn't include the smallest, earliest form of breast cancer found only by mammography -- ductal carcinoma in situ or DCIS.
If overdiagnosis is a problem in invasive cancer, you can imagine it might be a greater problem for a smaller, earlier form of cancer. Even mammography's old guard objects to having DCIS included in estimates of the amount of overdiagnosis.
Why do they object? Because so much of DCIS represents overdiagnosis, including it makes the estimate even higher.
It's time to get the science back in screening mammography and to recognize that mammographers may not be the ideal source for balanced information. It's too much like asking the dentists for balanced information about routine dental X-rays.
The opinions expressed in this commentary are solely those of H. Gilbert Welch.
