The world has an insatiable appetite for innovation. To feed this desire for technologic and scientific breakthroughs, nations invest in our celebrated universities. Tax and tuition dollars go to educate students -- the next generation of open-minded thinkers -- but also toward fostering research. After all, academia is the quintessential innovation incubator. Isn't it?
Early in 2012, the eminent magazine "Science" invited young scientists worldwide to answer the question: "How will the practice of science change in your lifetime?" One particularly pained (and not unrepresentative) reply was:
"The biggest challenge facing a generation of young scientists is breaking free of the shackles placed on them by their predecessors ... We are expected to fix broken peer-review systems riddled with small insular cliques ... We are expected not only to flourish but to be thankful for a funding structure equipped with scarce resources that are primarily used on contract science for the blessed few rather than discovery based on the merits of ideas ... We are expected to rise to this challenge and we're sure as hell going to give it our all," said Jeremy Block from Duke University Medical Center, Durham, North Carolina.
Consider the following statistics from the U.S., still representing over 40% of OECD (the Organisation for Economic Co-operation and Development, which represents many of the world's developed countries) R&D. Today, only 3% of principal investigators on federal grants are aged less than 36; in 1980 that was 18%. Only 14% of U.S. PhD graduates in biology land an academic position within five years of graduation. Although we know that some of the most novel ideas come from young people, we are not giving our best and brightest their intellectual independence until they are middle aged.
Read more: $30 gadget lets you control computer with your eyes
The problem, I believe, is that science has become unbalanced. What should be the ascendant end of the scale, the joy of producing surprising improvements in health and prosperity, has become outweighed by societal caution. That caution embodies the fear that science might not produce the immediate pay-offs that we expect from our investments.
Ironically, our desire for instant success is at odds with the reality of achieving transformational breakthroughs. Short-term expenditures that produce creative evolution are a far cry from the long-term investments that generate technical and scientific revolution. As John Gertner noted in his recent book about the innovation powerhouse Bell Laboratories, "One type of innovation (e.g. smartphone apps) creates a handful of jobs and modest revenues; the other (e.g. the transistor) ...creates millions of jobs and a long-lasting platform for societal wealth and well-being."
Caution has led governmental funding to become risk-averse. OECD countries have seen substantial declines in government sponsorship of R&D in the past generation -- down from 44% in 1981 to 30% in 2000. Long shots such as the NASA manned space flight program have been canceled and agencies have limited backing for anything that may slow economic growth, such as environmental and climate research.
At a time when governmental support for science in many OECD countries has not kept up with inflation, caution overrides our craving for originality. In today's funding climate, when 90% of applications requesting financial support for new ideas from most OECD governmental sources are turned down, peer review committees shift their support to work that is safe and incremental. Caution in the garb of regulation and litigiousness has driven almost all of the recent growth in industry R&D to Southeast Asia.
There are many approaches to re-tipping the balance toward creation and away from caution. First and foremost, we must be more willing to take risks. Originality must become as highly valued as linear progression. Our scientific portfolio must contain a higher proportion of reasonable long-shots, even while we acknowledge that these may never pay off.
Second, we must invest in promising young people as much or more than we invest in productive projects.
Third, funding should be directed to prototyping, meaning high-risk projects that when they fail, fail fast and fail smart (we learn from their failure).
Finally, we must teach young people to be innovative. Most scientists believe that creativity is innate, yet 30 years of research has demonstrated that novel thinking can be taught. In my recent book, "Innovation Generation," I describe a systematic approach to learning to think "outside the box." A central feature is discovering how to frame shift.
Normal thinking is constrained by habitual patterns which linguists call "frames." Frames are a structure of expectations that we use to interpret new information. For instance, if while sitting in a lecture hall, the person next to you sneezes then grabs your sleeve and wipes their nose on it, would you be shocked? Of course you would. The sneezer just disrupted agreed-upon social assumptions -- they broke your frame.
Frame shifting, what Albert Einstein referred to when he said, "No problem can be solved from the same level of consciousness that created it," allows for not just steps but leaps in thinking. Shifts in frames or paradigms led scientists in the 1860s to realize that the bacteria that they had been seeing through microscopes for almost 200 years were pathogens that caused specific diseases. Today, another paradigm shift has led us to realize that the millions of bacteria that inhabit our body cavities are not enemies but allies.
A shift in our frame about death from "terrifying and unspeakable" to "nothing is sure but death and taxes" (Benjamin Franklin), for example, might lead us to create bureaucratic systems for ensuring that every American has a living will, an act that would likely reduce the quarter of all Medicare expenditures spent in the last year of life.
Academic science remains a driver of societal transformation; with some frame shifting we could unleash even more global innovation.
The opinions expressed in this commentary are solely those of Roberta B. Ness
